\hypertarget{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer}{}\doxysection{Tokenizer Class Reference}
\label{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer}\index{Tokenizer@{Tokenizer}}
Inheritance diagram for Tokenizer\+:\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[height=3.000000cm]{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer}
\end{center}
\end{figure}
\doxysubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_aa536237e31fcb5fc57b2dc164d862cc5}{\+\_\+\+\_\+construct}} (\$content, \$config, \$eol\+Char=\textquotesingle{}\textbackslash{}n\textquotesingle{})
\item 
\mbox{\hyperlink{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_acf2f05f60b57bd67020d2259a2cf9982}{get\+Tokens}} ()
\item 
\mbox{\hyperlink{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_a8125932baf24dd98754e774dbb02e515}{replace\+Tabs\+In\+Token}} (\&\$token, \$prefix=\textquotesingle{} \textquotesingle{}, \$padding=\textquotesingle{} \textquotesingle{}, \$tab\+Width=\mbox{\hyperlink{_upper_case_constant_unit_test_8inc_a2eb6119331dfbe4aca20bd1107d44fdb}{null}})
\end{DoxyCompactItemize}
\doxysubsection*{Data Fields}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_aa377970f7a1e8fab9ed698e572fb3222}{\$scope\+Openers}} = \mbox{[}$\,$\mbox{]}
\item 
\mbox{\hyperlink{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_ad3ae70cc91d445980636874600462512}{\$end\+Scope\+Tokens}} = \mbox{[}$\,$\mbox{]}
\item 
\mbox{\hyperlink{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_af531c63799f56214ac75c963966e342f}{\$known\+Lengths}} = \mbox{[}$\,$\mbox{]}
\item 
\mbox{\hyperlink{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_ab7b7594ee9143d623a36f239d76fe584}{\$ignored\+Lines}} = \mbox{[}$\,$\mbox{]}
\end{DoxyCompactItemize}
\doxysubsection*{Protected Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_af9dc4a26a1f0fcd008f3a154c0945686}{is\+Minified\+Content}} (\$content, \$eol\+Char=\textquotesingle{}\textbackslash{}n\textquotesingle{})
\item 
\mbox{\hyperlink{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_a2605b7284198c41c0551eca215bf65e1}{tokenize}} (\$\mbox{\hyperlink{_array_declaration_unit_test_82_8inc_af67ca679ad2d29ae45cd6af97b927adf}{string}})
\item 
\mbox{\hyperlink{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_ae9feaa114cfdb387b421a0ebd8235d74}{process\+Additional}} ()
\end{DoxyCompactItemize}
\doxysubsection*{Protected Attributes}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_a49c7011be9c979d9174c52a8b83e5d8e}{\$config}} = \mbox{\hyperlink{_upper_case_constant_unit_test_8inc_a2eb6119331dfbe4aca20bd1107d44fdb}{null}}
\item 
\mbox{\hyperlink{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_aef0b9e1d77d38361f05d47b63c7403a9}{\$eol\+Char}} = \mbox{[}$\,$\mbox{]}
\item 
\mbox{\hyperlink{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_a72ead29e4317fbc4335fd3ba764e8b59}{\$tokens}} = \mbox{[}$\,$\mbox{]}
\item 
\mbox{\hyperlink{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_ad67c3542d2db407787c9b3dda8d43f3e}{\$num\+Tokens}} = 0
\end{DoxyCompactItemize}


\doxysubsection{Constructor \& Destructor Documentation}
\mbox{\Hypertarget{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_aa536237e31fcb5fc57b2dc164d862cc5}\label{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_aa536237e31fcb5fc57b2dc164d862cc5}} 
\index{Tokenizer@{Tokenizer}!\_\_construct@{\_\_construct}}
\index{\_\_construct@{\_\_construct}!Tokenizer@{Tokenizer}}
\doxysubsubsection{\texorpdfstring{\_\_construct()}{\_\_construct()}}
{\footnotesize\ttfamily \+\_\+\+\_\+construct (\begin{DoxyParamCaption}\item[{}]{\$content,  }\item[{}]{\$config,  }\item[{}]{\$eol\+Char = {\ttfamily \textquotesingle{}\textbackslash{}n\textquotesingle{}} }\end{DoxyParamCaption})}

Initialise and run the tokenizer.


\begin{DoxyParams}[1]{Parameters}
string & {\em \$content} & The content to tokenize, \\
\hline
\textbackslash{}\+PHP\+\_\+\+Code\+Sniffer\textbackslash{}\+Config  |  null & {\em \$config} & The config data for the run. \\
\hline
string & {\em \$eol\+Char} & The EOL char used in the content.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
void 
\end{DoxyReturn}

\begin{DoxyExceptions}{Exceptions}
{\em } & \\
\hline
\end{DoxyExceptions}
\mbox{\hyperlink{namespace_p_h_p___code_sniffer}{PHP\+\_\+\+Code\+Sniffer}}\textbackslash{}\+Exceptions\textbackslash{}\+Tokenizer\+Exception If the file appears to be minified. 

\doxysubsection{Member Function Documentation}
\mbox{\Hypertarget{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_acf2f05f60b57bd67020d2259a2cf9982}\label{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_acf2f05f60b57bd67020d2259a2cf9982}} 
\index{Tokenizer@{Tokenizer}!getTokens@{getTokens}}
\index{getTokens@{getTokens}!Tokenizer@{Tokenizer}}
\doxysubsubsection{\texorpdfstring{getTokens()}{getTokens()}}
{\footnotesize\ttfamily get\+Tokens (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}

Gets the array of tokens.

\begin{DoxyReturn}{Returns}
array 
\end{DoxyReturn}
\mbox{\Hypertarget{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_af9dc4a26a1f0fcd008f3a154c0945686}\label{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_af9dc4a26a1f0fcd008f3a154c0945686}} 
\index{Tokenizer@{Tokenizer}!isMinifiedContent@{isMinifiedContent}}
\index{isMinifiedContent@{isMinifiedContent}!Tokenizer@{Tokenizer}}
\doxysubsubsection{\texorpdfstring{isMinifiedContent()}{isMinifiedContent()}}
{\footnotesize\ttfamily is\+Minified\+Content (\begin{DoxyParamCaption}\item[{}]{\$content,  }\item[{}]{\$eol\+Char = {\ttfamily \textquotesingle{}\textbackslash{}n\textquotesingle{}} }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [protected]}}

Checks the content to see if it looks minified.


\begin{DoxyParams}[1]{Parameters}
string & {\em \$content} & The content to tokenize. \\
\hline
string & {\em \$eol\+Char} & The EOL char used in the content.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
boolean 
\end{DoxyReturn}
\mbox{\Hypertarget{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_ae9feaa114cfdb387b421a0ebd8235d74}\label{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_ae9feaa114cfdb387b421a0ebd8235d74}} 
\index{Tokenizer@{Tokenizer}!processAdditional@{processAdditional}}
\index{processAdditional@{processAdditional}!Tokenizer@{Tokenizer}}
\doxysubsubsection{\texorpdfstring{processAdditional()}{processAdditional()}}
{\footnotesize\ttfamily process\+Additional (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [abstract]}, {\ttfamily [protected]}}

Performs additional processing after main tokenizing.

\begin{DoxyReturn}{Returns}
void 
\end{DoxyReturn}


Reimplemented in \mbox{\hyperlink{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_j_s_ae9feaa114cfdb387b421a0ebd8235d74}{JS}}, and \mbox{\hyperlink{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_p_h_p_ae9feaa114cfdb387b421a0ebd8235d74}{PHP}}.

\mbox{\Hypertarget{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_a8125932baf24dd98754e774dbb02e515}\label{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_a8125932baf24dd98754e774dbb02e515}} 
\index{Tokenizer@{Tokenizer}!replaceTabsInToken@{replaceTabsInToken}}
\index{replaceTabsInToken@{replaceTabsInToken}!Tokenizer@{Tokenizer}}
\doxysubsubsection{\texorpdfstring{replaceTabsInToken()}{replaceTabsInToken()}}
{\footnotesize\ttfamily replace\+Tabs\+In\+Token (\begin{DoxyParamCaption}\item[{\&}]{\$token,  }\item[{}]{\$prefix = {\ttfamily \textquotesingle{}~\textquotesingle{}},  }\item[{}]{\$padding = {\ttfamily \textquotesingle{}~\textquotesingle{}},  }\item[{}]{\$tab\+Width = {\ttfamily \mbox{\hyperlink{_upper_case_constant_unit_test_8inc_a2eb6119331dfbe4aca20bd1107d44fdb}{null}}} }\end{DoxyParamCaption})}

Replaces tabs in original token content with spaces.

Each tab can represent between 1 and \$config-\/\texorpdfstring{$>$}{>}tab\+Width spaces, so this cannot be a straight string replace. The original content is placed into an orig\+\_\+content index and the new token length is also set in the length index.


\begin{DoxyParams}[1]{Parameters}
array & {\em \$token} & The token to replace tabs inside. \\
\hline
string & {\em \$prefix} & The character to use to represent the start of a tab. \\
\hline
string & {\em \$padding} & The character to use to represent the end of a tab. \\
\hline
int & {\em \$tab\+Width} & The number of spaces each tab represents.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
void 
\end{DoxyReturn}
\mbox{\Hypertarget{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_a2605b7284198c41c0551eca215bf65e1}\label{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_a2605b7284198c41c0551eca215bf65e1}} 
\index{Tokenizer@{Tokenizer}!tokenize@{tokenize}}
\index{tokenize@{tokenize}!Tokenizer@{Tokenizer}}
\doxysubsubsection{\texorpdfstring{tokenize()}{tokenize()}}
{\footnotesize\ttfamily tokenize (\begin{DoxyParamCaption}\item[{}]{\$string }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [abstract]}, {\ttfamily [protected]}}

Creates an array of tokens when given some content.


\begin{DoxyParams}[1]{Parameters}
string & {\em \$string} & The string to tokenize.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
array 
\end{DoxyReturn}


Reimplemented in \mbox{\hyperlink{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_c_s_s_a2605b7284198c41c0551eca215bf65e1}{CSS}}, \mbox{\hyperlink{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_j_s_a2605b7284198c41c0551eca215bf65e1}{JS}}, and \mbox{\hyperlink{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_p_h_p_a2605b7284198c41c0551eca215bf65e1}{PHP}}.



\doxysubsection{Field Documentation}
\mbox{\Hypertarget{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_a49c7011be9c979d9174c52a8b83e5d8e}\label{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_a49c7011be9c979d9174c52a8b83e5d8e}} 
\index{Tokenizer@{Tokenizer}!\$config@{\$config}}
\index{\$config@{\$config}!Tokenizer@{Tokenizer}}
\doxysubsubsection{\texorpdfstring{\$config}{$config}}
{\footnotesize\ttfamily \$config = \mbox{\hyperlink{_upper_case_constant_unit_test_8inc_a2eb6119331dfbe4aca20bd1107d44fdb}{null}}\hspace{0.3cm}{\ttfamily [protected]}}

\mbox{\Hypertarget{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_ad3ae70cc91d445980636874600462512}\label{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_ad3ae70cc91d445980636874600462512}} 
\index{Tokenizer@{Tokenizer}!\$endScopeTokens@{\$endScopeTokens}}
\index{\$endScopeTokens@{\$endScopeTokens}!Tokenizer@{Tokenizer}}
\doxysubsubsection{\texorpdfstring{\$endScopeTokens}{$endScopeTokens}}
{\footnotesize\ttfamily \$end\+Scope\+Tokens = \mbox{[}$\,$\mbox{]}}

\mbox{\Hypertarget{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_aef0b9e1d77d38361f05d47b63c7403a9}\label{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_aef0b9e1d77d38361f05d47b63c7403a9}} 
\index{Tokenizer@{Tokenizer}!\$eolChar@{\$eolChar}}
\index{\$eolChar@{\$eolChar}!Tokenizer@{Tokenizer}}
\doxysubsubsection{\texorpdfstring{\$eolChar}{$eolChar}}
{\footnotesize\ttfamily \$eol\+Char = \mbox{[}$\,$\mbox{]}\hspace{0.3cm}{\ttfamily [protected]}}

\mbox{\Hypertarget{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_ab7b7594ee9143d623a36f239d76fe584}\label{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_ab7b7594ee9143d623a36f239d76fe584}} 
\index{Tokenizer@{Tokenizer}!\$ignoredLines@{\$ignoredLines}}
\index{\$ignoredLines@{\$ignoredLines}!Tokenizer@{Tokenizer}}
\doxysubsubsection{\texorpdfstring{\$ignoredLines}{$ignoredLines}}
{\footnotesize\ttfamily \$ignored\+Lines = \mbox{[}$\,$\mbox{]}}

\mbox{\Hypertarget{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_af531c63799f56214ac75c963966e342f}\label{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_af531c63799f56214ac75c963966e342f}} 
\index{Tokenizer@{Tokenizer}!\$knownLengths@{\$knownLengths}}
\index{\$knownLengths@{\$knownLengths}!Tokenizer@{Tokenizer}}
\doxysubsubsection{\texorpdfstring{\$knownLengths}{$knownLengths}}
{\footnotesize\ttfamily \$known\+Lengths = \mbox{[}$\,$\mbox{]}}

\mbox{\Hypertarget{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_ad67c3542d2db407787c9b3dda8d43f3e}\label{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_ad67c3542d2db407787c9b3dda8d43f3e}} 
\index{Tokenizer@{Tokenizer}!\$numTokens@{\$numTokens}}
\index{\$numTokens@{\$numTokens}!Tokenizer@{Tokenizer}}
\doxysubsubsection{\texorpdfstring{\$numTokens}{$numTokens}}
{\footnotesize\ttfamily \$num\+Tokens = 0\hspace{0.3cm}{\ttfamily [protected]}}

\mbox{\Hypertarget{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_aa377970f7a1e8fab9ed698e572fb3222}\label{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_aa377970f7a1e8fab9ed698e572fb3222}} 
\index{Tokenizer@{Tokenizer}!\$scopeOpeners@{\$scopeOpeners}}
\index{\$scopeOpeners@{\$scopeOpeners}!Tokenizer@{Tokenizer}}
\doxysubsubsection{\texorpdfstring{\$scopeOpeners}{$scopeOpeners}}
{\footnotesize\ttfamily \$scope\+Openers = \mbox{[}$\,$\mbox{]}}

\mbox{\Hypertarget{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_a72ead29e4317fbc4335fd3ba764e8b59}\label{class_p_h_p___code_sniffer_1_1_tokenizers_1_1_tokenizer_a72ead29e4317fbc4335fd3ba764e8b59}} 
\index{Tokenizer@{Tokenizer}!\$tokens@{\$tokens}}
\index{\$tokens@{\$tokens}!Tokenizer@{Tokenizer}}
\doxysubsubsection{\texorpdfstring{\$tokens}{$tokens}}
{\footnotesize\ttfamily \$tokens = \mbox{[}$\,$\mbox{]}\hspace{0.3cm}{\ttfamily [protected]}}



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
C\+:/workspace/\+Proyecto PHP/project/vendor/squizlabs/php\+\_\+codesniffer/src/\+Tokenizers/\mbox{\hyperlink{squizlabs_2php__codesniffer_2src_2_tokenizers_2_tokenizer_8php}{Tokenizer.\+php}}\end{DoxyCompactItemize}
